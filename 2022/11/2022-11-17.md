# 2022. 11. 17.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰 필터 레퍼런스

#### Stop 토큰 필터

토큰 스트림에서 [불용어][wikipedia-stop-word](stop words)를 제거한다.

커스터마이즈하지 않으면 필터는 기본적으로 다음 영어 단어들을 제거한다:

`a`, `an`, `and`, `are`, `as`, `at`, `be`, `but`, `by`, `for`, `if`, `in`, `into`, `is`, `it`, `no`, `not`, `of`, `on`, `or`, `such`, `that`, `the`, `their`, `then`, `there`, `these`, `they`, `this`, `to`, `was`, `will`, `with`

`stop` 필터는 영어 외에도 미리 정의된 [몇몇 언어에 대한 불용어 목록][stop-words-for-lang]을 지원한다. 배열이나 파일로 고유한 불용어 목록을 지정할 수도 있다.

`stop` 필터는 Lucene의 [StopFilter][lucene-stop-filter]를 사용한다.

##### 예제

다음 분석 API 요청은 `stop` 필터를 사용해 `a quick fox jumps over the lazy dog`에서 `a`와 `the`를 제거한다:

```http
GET /_analyze
{
  "tokenizer": "standard",
  "filter": [ "stop" ],
  "text": "a quick fox jumps over the lazy dog"
}
```

필터는 다음 토큰을 만들어낸다:

```
[ quick, fox, jumps, over, lazy, dog ]
```

##### 분석기에 추가

다음 [인덱스 생성 API][create-index-api] 요청은 `stop` 필터를 사용해 새 [커스텀 분석기][custom-analyzer]를 구성한다.

```http
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "whitespace",
          "filter": [ "stop" ]
        }
      }
    }
  }
}
```

##### 구성 가능한 파라미터

**`stopwords`**

(Optional, string or array of strings) `_arabic_`이나 `_thai_`와 같은 언어 값. 기본값은 [`_english_`](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stop-tokenfilter.html#english-stop-words)이다.

각 언어 값은 Lucene에 미리 정의된 불용어 목록에 대응된다. 지원되는 언어 값과 각각의 불용어에 대해서는 [언어별 불용어](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stop-tokenfilter.html#analysis-stop-tokenfilter-stop-words-by-lang)를 참고하라.

불용어 배열을 받을 수도 있다.

빈 불용어 목록은 `_none_`을 사용하라.

**`stopwords_path`**

(Optional, string) 제거할 불용어 목록이 포함된 파일 경로.

이 경로는 절대 경로이거나 `config` 위치에 대한 상대 경로여야 하며 파일은 UTF-8로 인코딩돼야 한다. 파일의 각 불용어는 개행으로 구분돼야 한다.

**`ignore_case`**

(Optional, Boolean) `true`이면 대소문자를 구분하지 않고 불용어를 일치시킨다. 예를 들어, `true`인 경우 불용어 `the`는 `The`, `THE`, 혹은 `the`와 일치하고 이들을 제거한다. 기본값은 `false`이다.

**`remove_trailing`**

(Optional, Boolean) `true`이면 스트림의 마지막 토큰이 불용어인 경우 제거한다. 기본값은 `true`이다.

필터를 [완성 제안자](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-suggesters.html#completion-suggester)와 함께 사용할 때는 이 파라미터가 `false`여야 한다. 그래야 다른 불용어를 제거하면서도 `green a`와 같은 쿼리가 `green apple`에 일치하고 이를 제안하도록 한다.

##### 커스터마이즈

`stop` 필터를 커스터마이즈하려면 이를 복제해 새 커스텀 토큰 필터를 만들면 된다. 구성 가능한 파라미터를 사용해 변형할 수 있다.

예를 들어, 다음 요청은 대소문자를 구분하지 않고 [`_english_`](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stop-tokenfilter.html#english-stop-words) 불용어 목록에서 불용어를 제거하는 `stop` 필터를 구성한다:

```http
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "default": {
          "tokenizer": "whitespace",
          "filter": [ "my_custom_stop_words_filter" ]
        }
      },
      "filter": {
        "my_custom_stop_words_filter": {
          "type": "stop",
          "ignore_case": true
        }
      }
    }
  }
}
```

고유한 불용어 목록을 지정할 수도 있다. 예를 들어, 다음 요청은 대소문자를 구분하지 않고 `and`, `is`, `the`만 제거하는 커스텀 `stop` 필터를 만든다:

```http
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "default": {
          "tokenizer": "whitespace",
          "filter": [ "my_custom_stop_words_filter" ]
        }
      },
      "filter": {
        "my_custom_stop_words_filter": {
          "type": "stop",
          "ignore_case": true,
          "stopwords": [ "and", "is", "the" ]
        }
      }
    }
  }
}
```

##### 언어별 불용어

다음 목록은 `stopwords` 파라미터에 대해 지원되는 언어 값과 미리 정의된 불용어에 대한 링크이다.

**`_arabic_`**

[Arabic stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ar/stopwords.txt)

**`_armenian_`**

[Armenian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/hy/stopwords.txt)

**`_basque_`**

[Basque stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/eu/stopwords.txt)

**`_bengali_`**

[Bengali stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/bn/stopwords.txt)

**`_brazilian_` (Brazilian Portuguese)**

[Brazilian Portuguese stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/br/stopwords.txt)

**`_bulgarian_`**

[Bulgarian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/bg/stopwords.txt)

**`_catalan_`**

[Catalan stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ca/stopwords.txt)

**`_cjk_` (Chinese, Japanese, and Korean)**

[CJK stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/cjk/stopwords.txt)

**`_czech_`**

[Czech stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/cz/stopwords.txt)

**`_danish_`**

[Danish stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/danish_stop.txt)

**`_dutch_`**

[Dutch stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/dutch_stop.txt)

**`_english_`**

[English stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java#L46)

**`_estonian_`**

[Estonian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/et/stopwords.txt)

**`_finnish_`**

[Finnish stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/finnish_stop.txt)

**`_french_`**

[French stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/french_stop.txt)

**`_galician_`**

[Galician stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/gl/stopwords.txt)

**`_german_`**

[German stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/german_stop.txt)

**`_greek_`**

[Greek stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/el/stopwords.txt)

**`_hindi_`**

[Hindi stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/hi/stopwords.txt)

**`_hungarian_`**

[Hungarian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/hungarian_stop.txt)

**`_indonesian_`**

[Indonesian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/id/stopwords.txt)

**`_irish_`**

[Irish stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ga/stopwords.txt)

**`_italian_`**

[Italian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/italian_stop.txt)

**`_latvian_`**

[Latvian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/lv/stopwords.txt)

**`_lithuanian_`**

[Lithuanian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/lt/stopwords.txt)

**`_norwegian_`**

[Norwegian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/norwegian_stop.txt)

**`_persian_`**

[Persian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/fa/stopwords.txt)

**`_portuguese_`**

[Portuguese stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/portuguese_stop.txt)

**`_romanian_`**

[Romanian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ro/stopwords.txt)

**`_russian_`**

[Russian stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/russian_stop.txt)

**`_sorani_`**

[Sorani stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/ckb/stopwords.txt)

**`_spanish_`**

[Spanish stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/spanish_stop.txt)

**`_swedish_`**

[Swedish stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/snowball/swedish_stop.txt)

**`_thai_`**

[Thai stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/th/stopwords.txt)

**`_turkish_`**

[Turkish stop words](https://github.com/apache/lucene-solr/blob/master/lucene/analysis/common/src/resources/org/apache/lucene/analysis/tr/stopwords.txt)



[wikipedia-stop-word]: https://en.wikipedia.org/wiki/Stop_words
[stop-words-for-lang]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stop-tokenfilter.html#analysis-stop-tokenfilter-stop-words-by-lang
[lucene-stop-filter]: https://lucene.apache.org/core/8_7_0/core/org/apache/lucene/analysis/StopFilter.html
[create-index-api]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/indices-create-index.html
[custom-analyzer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-custom-analyzer.html