# 2022. 11. 02.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰 필터 레퍼런스

#### MinHash 토큰 필터

[MinHash][wikipedia-min-hash] 기술을 사용해 토큰 스트림에 대한 시그니처를 만들어낸다. MinHash 시그니처를 사용해 도큐먼트의 유사도를 평가할 수 있다. [`min_hash` 토큰 필터를 사용해 유사도 검색][using-min-hash-for-similarity-search]을 참고하라.

`min_hash` 필터는 토큰 스트림에 대해 다음 연산을 차례로 수행한다:

1. 스트림의 각 토큰을 해시한다.
2. 해시를 버킷에 할당한다. 각 버킷에서 가장 작은 해시만 유지한다.
3. 각 버킷에서 가장 작은 해시들만을 토큰 스트림으로 출력한다.

이 필터는 Lucene의 [MinHashFilter][lucene-min-hash-filter]를 사용한다.

##### 구성 가능한 파라미터

**`bucket_count`**

(Optional, integer) 해시가 할당될 버킷의 수. 기본값은 `512`이다.

**`hash_count`**

(Optional, integer) 스트림의 각 토큰을 해시할 경우의 수. 기본값은 `1`이다.

**`hash_set_size`**

(Optional, integer) 각 버킷에서 유지할 해시의 수. 기본값은 `1`이다. 버킷의 해시는 가장 작은 해시부터 시작해 오름차순으로 유지된다. 

**`with_rotation`**

(Optional, Boolean) `true`이면 필터는 `hash_set_size`가 1일 때 빈 버킷을 우측으로 순환했을 때 가장 먼저 등장하는 비어있지 않은 값으로 채운다. `bcuekt_count` 인자가 1보다 크면 이 파라미터의 기본값은 `true`이고 그 외의 경우 이 파라미터의 기본값은 `false`이다.

##### `min_hash` 필터를 구성하는 팁

* `min_hash` 필터 입력 토큰은 주로 [shingle 토큰 필터][shingle-token-filter]에서 만들어진 k-word shingle이다. 충분히 큰 `k`를 선택해야 임의의 snigle이 주어졌을 때 도큐먼트에서 등장할 확률이 낮아진다. 동시에, 내부적으로 각 shingle은 128비트 해시로 해시되므로 충분히 작은 `k`를 선택해야 가능한 모든 서로 다른 k-word shingle들이 최소한의 충돌로 128비트 해시로 해시된다.
* `hash_count`, `bucket_count`와 `hash_set_size`에 대해 서로 다른 인자들로 테스트해볼 것을 권장한다.
  * 정확도를 높이려면 `bucket_count`나 `hash_set_size` 인자를 증가시켜라. `bucket_count`와 `hash_set_size` 값이 높을수록 서로 다른 토큰들이 서로 다른 버킷에 인덱스될 가능성이 높아진다.
  * 더 잘 나오도록(recall) 하려면, 예를 들어, `hash_count`를  `2`로 설정하면 각 토큰을 서로 두 가지 다른 방법으로 해시해서 검색에 대한 잠재적 후보의 수를 늘린다.

* 기본적으로 `min_hash` 필터는 각 도큐먼트에 대해 512개의 토큰을 만들어낸다. 각 토큰은 16바이트 크기이다. 즉, 각 도큐먼트의 크기가 약 8Kb 증가한다.
* `min_hash` 필터는 Jaccard 유사도에 사용된다. 죽, 도큐먼트가 특정 토큰을 얼마나 많이 포함하는지는 관계 없이 포함하는지 포함하지 않는지가 중요하다.

##### 유사도 검색에 `min_hash` 사용하기

`min_hash` 토큰 필터로 유사도 검색을 위해 도큐먼트를 해시할 수 있다. 유사도 검색 또는 인접 이웃(nearest neighbor) 검색은 복잡한 문제다. 단순한(naive) 해결법은 쿼리 도큐먼트와 인덱스의 모든 도큐먼트를 짝지어 일일이 비교하는 것이다. 인덱스가 크다면 엄두도 못낼 연산이다. 유사도 검색을 더 실용적이고 계산적으로 실현 가능한 몇 가지 인접 이웃 검색 방법이 개발돼왔다. 도큐먼트 해싱도 이 방법 중 하나에 속한다.

비슷한 도큐먼트일수록 같은 해시 코드를 만들어 같은 해시 버킷에 들어가고, 그렇지 않은 도큐먼트는 다른 해시 버킷으로 들어갈 가능성이 높도록 도큐먼트를 해시한다. 이 유형의 해싱은 지역성 민감 해싱(locality sensitive hashing, LSH)로도 알려져 있다.

도큐먼트 간의 유사도를 무엇으로 기준삼을 지에 따라 다양한  LSH 함수가 [제안됐다][lsh-function-proposal]. [Jaccard 유사도][wikipedia-jaccard-index]의 경우 인기 있는 LSH 함수는 [MinHash][wikipedia-min-hash]이다. MinHash가 도큐먼트에 대한 시그니처를 만들어내는 일반적인 아이디어는 전체 인덱스 어휘(어휘에 무작위로 숫자를 매긴)에 무작위 순열을 적용하고 도큐먼트에 대한 순열의 최솟값을 기록하는 것이다(도큐먼트에 나타난 단어의 최솟값). 순열은 여러번 실행된다. 모든 최솟값을 조합한 것이 도큐먼트의 시그니처를 이룬다.

실질적으로는 무작위 순열 대신 몇 가지 해시 함수가 선택된다. 해시 함수는 각 도큐먼트의 토큰에 대한 해시 코드를 계산하고 이들 중 가장 작은 해시 코드를 선택한다. 모든 해시 함수들의 최소 해시 코드들을 조합해 도큐먼트에 대한 시그니처로 만든다.

##### 커스터마이즈해 분석기에 추가

`min_hash` 필터를 커스터마이즈하려면 이를 복제해 새 커스텀 토큰 필터로 만들면 된다. 구성 가능한 파라미터를 사용해 변형할 수 있다.

예를 들어, 다음 [인덱스 생성 API][create-index-api] 요청은 다음 커스텀 토큰 필터를 사용해 새 [커스텀 분석기][custom-analyzer]를 구성한다:

* `my_shingle_filter`는 다섯 단어 shingle만을 출력하는 커스텀 [`shingle` 필터][shingle-filter]이다.
* `my_minhash_filter`는 각 다섯 단어 shingle을 한번에 해시하는 커스텀 `min_hash` 필터이다. 그 다음 이 해시들을 512 버킷에 할당하고 각 버킷에서 가장 작은 해시만 유지한다.

다음 요청은 커스텀 분석기를 `fingerprint` 필드 매핑에 할당한다:

```http
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "filter": {
        "my_shingle_filter": {      // 1. 다섯 단어 shingle을 출력하는 커스텀 shingle 필터를 구성한다.
          "type": "shingle",
          "min_shingle_size": 5,
          "max_shingle_size": 5,
          "output_unigrams": false
        },
        "my_minhash_filter": {
          "type": "min_hash",
          "hash_count": 1,          // 2. 스트림의 각 다섯 단어 shingle은 한번에 해시된다.
          "bucket_count": 512,      // 3. 해시들은 512 버킷에 할당된다.
          "hash_set_size": 1,       // 4. 버킷에서 가장 작은 해시들만 유지된다.
          "with_rotation": true     // 5. 이 필터는 빈 버킷을 인접한 버킷의 값으로 채운다.
        }
      },
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "my_shingle_filter",
            "my_minhash_filter"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "fingerprint": {
        "type": "text",
        "analyzer": "my_analyzer"
      }
    }
  }
}
```





[wikipedia-min-hash]: https://en.wikipedia.org/wiki/MinHash
[using-min-hash-for-similarity-search]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-minhash-tokenfilter.html#analysis-minhash-tokenfilter-similarity-search
[lucene-min-hash-filter]: https://lucene.apache.org/core/8_7_0/analyzers-common/org/apache/lucene/analysis/minhash/MinHashFilter.html
[lsh-function-proposal]: https://arxiv.org/abs/1408.2927
[wikipedia-jaccard-index]: https://en.wikipedia.org/wiki/Jaccard_index
[create-index-api]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/indices-create-index.html
[custom-analyzer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-custom-analyzer.html
[shingle-filter]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-shingle-tokenfilter.html