# 2022. 09. 23.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰화기 레퍼런스

#### Character group 토큰화기

`char_group` 토큰화기는 텍스트를 집합에 정의된 문자가 나타나는 곳마다 텀으로 나눈다. 단순한 커스텀 토큰화가 필요하면서 [`pattern` 토큰화기][pattern-tokenizer]의 오버헤드를 수용할 수 없는 경우에 유용하다.

##### 구성

`char_group` 토큰화기는 하나의 파라미터를 받는다:

| 파라미터            | 설명                                                         |
| ------------------- | ------------------------------------------------------------ |
| `tokenize_on_chars` | 문자열을 토큰화할 문자의 목록. 이 목록의 문자가 나타날 때마다 새 토큰이 시작된다. `-`와 같은 단일 문자나 `whitespace`, `letter`, `digit`, `punctuation`, `symbol`과 같은 문자 그룹을 받는다. |
| `max_token_length`  | 최대 토큰 길이. 토큰이 이 길이를 초과하면 `max_token_length` 간격으로 나뉜다. 기본값은 255이다. |

##### 예제 출력

```http
POST _analyze
{
  "tokenizer": {
    "type": "char_group",
    "tokenize_on_chars": [
      "whitespace",
      "-",
      "\n"
    ]
  },
  "text": "The QUICK brown-fox"
}
```

다음을 반환한다:

```json
{
  "tokens": [
    {
      "token": "The",
      "start_offset": 0,
      "end_offset": 3,
      "type": "word",
      "position": 0
    },
    {
      "token": "QUICK",
      "start_offset": 4,
      "end_offset": 9,
      "type": "word",
      "position": 1
    },
    {
      "token": "brown",
      "start_offset": 10,
      "end_offset": 15,
      "type": "word",
      "position": 2
    },
    {
      "token": "fox",
      "start_offset": 16,
      "end_offset": 19,
      "type": "word",
      "position": 3
    }
  ]
}
```



[pattern-tokenizer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-pattern-tokenizer.html