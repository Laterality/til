# 2022. 09. 08.

## Elasticsearch(7.10)

### 텍스트 분석 - 내장 분석기 레퍼런스

#### Fingerprint 분석기

`fingerprint` 분석기는 OpenRefine 프로젝트에서 클러스터링을 보조하기 위해 사용하는 [fingerprint 알고리즘][openrefine-fingerprint]을 구현한다.

입력 텍스트는 소문자로 변환되고, 확장 문자를 제거하기 위해 정규화되며, 정렬되고, 중복을 제거해 단일 토큰으로 이어붙인다. 불용어 목록이 구성되면 불용어도 제거된다.

##### 예제

```http
POST _analyze
{
  "analyzer": "fingerprint",
  "text": "Yes yes, Gödel said this sentence is consistent and."
}
```

위 문장은 다음과 같은 단일 텀으로 만들어진다:

```
[ and consistent godel is said sentence this yes ]
```

##### 구성

`fingerprint` 분석기는 다음 파라미터를 받는다:

| 파라미터          | 설명                                                         |
| ----------------- | ------------------------------------------------------------ |
| `separator`       | 텀을 이어붙이는데 사용할 문자. 기본값은 공백이다.            |
| `max_output_size` | 만들어낼 최대 토큰 크기. 기본값은 `255`이다. 이 크기보다 큰 토큰들은 제외된다. |
| `stopwords`       | `_english_`처럼 미리 정의된 불용어 목록이나 불용어 목록을 가진 배열. 기본값은 `_none_`이다. |
| `stopwords_path`  | 불용어를 가진 파일 경로.                                     |

불용어 구성에 관한 더 자세한 내용은 [Stop 토큰 필터][stop-token-filter]를 참고하라.

##### 예제 구성

이 예제에서는 미리 정의된 영어 불용어 목록을 사용하도록 `fingerprint` 분석기를 구성한다:

```http
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_fingerprint_analyzer": {
          "type": "fingerprint",
          "stopwords": "_english_"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_fingerprint_analyzer",
  "text": "Yes yes, Gödel said this sentence is consistent and."
}
```

위 예제는 다음 텀을 만들어낸다:

```
[ consistent godel said sentence yes ]
```

##### 정의

`fingerprint` 토큰화기는 다음으로 구성된다:

**토큰화기**

- [Standard Tokenizer](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-standard-tokenizer.html)

**토큰 필터(순서대로)**

- [소문자 토큰 필터](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-lowercase-tokenfilter.html)
- [ASCII 폴딩](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-asciifolding-tokenfilter.html)
- [Stop 토큰 필터](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stop-tokenfilter.html) (기본값은 비활성화)
- [Fingerprint](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-fingerprint-tokenfilter.html)

구성 파라미터 이상으로 `fingerprint` 분석기를 커스터마이즈해야 한다면 `custom` 분석기로 다시 만들고 변형하면 된다. 주로 토큰 필터를 추가한다. 이렇게 함으로써 내장 `fingerprint` 분석기를 다시 만들고 이를 추가적인 커스터마이즈의 시작점으로 사용할 수 있다:

```http
PUT /fingerprint_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "rebuilt_fingerprint": {
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "asciifolding",
            "fingerprint"
          ]
        }
      }
    }
  }
}
```



[openrefine-fingerprint]: https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth#fingerprint
[stop-token-filter]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stop-tokenfilter.html