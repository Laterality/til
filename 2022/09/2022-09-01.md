# 2022. 09. 01.

## Elasticsearch(7.10)

### 텍스트 분석 - 텍스트 분석 구성

#### 커스텀 분석기 생성

##### 예제 구성

다음을 조합한 예제가 있다:

**문자 필터**

- [HTML Strip 문자 필터](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-htmlstrip-charfilter.html)

**토큰화기**

- [Standard 토큰화기](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-standard-tokenizer.html)

**토큰 필터**

- [Lowercase 토큰 필터](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-lowercase-tokenfilter.html)
- [ASCII-Folding 토큰 필터](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-asciifolding-tokenfilter.html)

```http
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": {
          "type": "custom", // 1. `type`을 `custom`으로 설정해 Elasticsearch에 커스텀 분석기를 정의한다는 것을 알린다. 내장 분석기인 경우에는 `standard`나 `simple`처럼 내장 분석기 이름을 `type`에 설정한다.
          "tokenizer": "standard",
          "char_filter": [
            "html_strip"
          ],
          "filter": [
            "lowercase",
            "asciifolding"
          ]
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "Is this <b>déjà vu</b>?"
}
```

위 예제는 다음 텀을 만든다:

```
[ is, this, deja, vu ]
```

이전 예제는 토큰화기, 토큰 필터, 문자 필터를 기본 구성으로 사용했지만 각각을 직접 구성한 버전으로 커스텀 분석기에서 사용할 수 있다.

다음은 아래를 조합한 더 복잡한 예제이다:

- **문자 필터**

  [Mapping Character Filter](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-mapping-charfilter.html), configured to replace `:)` with `_happy_` and `:(` with `_sad_`

- **토큰화기**

  [Pattern Tokenizer](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-pattern-tokenizer.html), configured to split on punctuation characters

- **토큰 필터**

  [Lowercase Token Filter](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-lowercase-tokenfilter.html)[Stop Token Filter](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stop-tokenfilter.html), configured to use the pre-defined list of English stop words

```http
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": { // 1. 인덱스에 기본 커스텀 분석기 `my_custom_analyzer`를 할당한다. 이 분석기는 요청 뒷부분에 정의된 커스텀 토큰화기, 문자 필터, 토큰 필터를 사용한다.
          "type": "custom",
          "char_filter": [
            "emoticons"
          ],
          "tokenizer": "punctuation",
          "filter": [
            "lowercase",
            "english_stop"
          ]
        }
      },
      "tokenizer": {
        "punctuation": { // 2. 커스텀 `punctuation` 토큰화기를 정의한다.
          "type": "pattern",
          "pattern": "[ .,!?]"
        }
      },
      "char_filter": {
        "emoticons": { // 3. 커스텀 `emoticon` 문자 필터를 정의한다.
          "type": "mapping",
          "mappings": [
            ":) => _happy_",
            ":( => _sad_"
          ]
        }
      },
      "filter": {
        "english_stop": { // 4. 커스텀 `english_stop` 토큰 필터를 정의한다.
          "type": "stop",
          "stopwords": "_english_"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "I'm a :) person, and you?"
}
```

위 예제는 다음 텀을 만든다:

```
[ i'm, _happy_, person, you ]
```

