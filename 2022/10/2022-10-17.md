# 2022. 10. 17.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰 필터 레퍼런스

#### Delimited payload 토큰 필터

> 예전 이름인 `delimitied_payload_filter`는 사용 중지(deprecated)됐으며 새 인덱스에서 사용돼선 안된다. `delimited_payload`를 사용하라.

토큰 스트림을 토큰과 명시된 구분자에 기반한 페이로드로 나눈다.

예를 들어, `|`를 구분자로 하여 `the|1 quick|2 fox|3`를 `delimited_payload`를 사용해 나누면 토큰은 `the`, `quick`, `fox`가 되고 페이로드는 각각 `1`, `2`, `3`가 된다.

이 필터는 Lucene의 [DelimitedPayloadTokenFilter][lucene-delimited-payload-token-filter]를 사용한다.

> ###### 페이로드
>
> 페이로드는 토큰 위치(position)에 연관된 사용자 정의 바이너리 데이터로, Base64 인코딩된 바이트로 저장된다.
>
> Elasticsearch는 기본적으로 토큰 페이로드를 저장하지 않는다. 페이로드를 저장하려면 다음과 같이 해야 한다:
>
> * 페이로드를 저장하는 필드의 [`term_vector`][term-vector] 매핑 파라미터를 `with_positions_payloads`나 `with_positions_offsets_payloads`로 설정한다.
> * `delimited_payload` 필터를 가진 인덱스 분석기를 사용한다.
>
> [텀 벡터 API][term-vector-api]를 사용해 저장된 페이로드를 볼 수 있다.

##### 예제

다음 [분석 API][analyze-api] 요청은 구분자가 `|`인  `delimited_payload` 필터를 사용해 `the|0 brown|10 fox|5 is|0 quick|10`를 토큰과 페이로드로 나눈다.

```http
GET _analyze
{
  "tokenizer": "whitespace",
  "filter": ["delimited_payload"],
  "text": "the|0 brown|10 fox|5 is|0 quick|10"
}
```

필터는 다음 토큰을 만들어낸다:

```
[ the, brown, fox, is, quick ]
```

분석 API는 저장된 페이로드를 반환하지 않는다는 점을 기억하라. 반환된 페이로드에 관해서는 [저장된 페이로드 반환][return-stored-payload]를 참고하라.

##### 분석기에 추가

다음 [인덱스 생성 API][create-index-api] 요청은 `delimited_payload` 필터를 사용해 새 [커스텀 분석기][custom-analyzer]를 구성한다.

```http
PUT delimited_payload
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_delimited_payload": {
          "tokenizer": "whitespace",
          "filter": [ "delimited_payload" ]
        }
      }
    }
  }
}
```

##### 구성 가능한 파라미터

**`delimiter`**

(선택, string) 페이로드에서 토큰을 구분하는 데 사용할 문자. 기본값은 `|`이다.

**`encoding`**

(선택, string) 저장된 페이로드의 데이터 타입. 유효한 값은 다음과 같다:

- **`float`**

  (기본값) 부동소수점

- **`identity`**

  문자

- **`int`**

  정수

##### 커스터마이즈해 분석기에 추가

`delimited_payload` 필터를 커스터마이즈하려면 이를 복제해 새 커스텀 토큰 필터를 만들면 된다. 구성 가능한 파라미터를 사용해 변형할 수 있다.

예를 들어, 다음 [인덱스 생성 API][create-index-api] 요청은 커스텀 `delimited_payload` 필터를 사용해 새 [커스텀 분석기][custom-analyzer]를 구성한다. 커스텀 `delimited_payload` 필터는 `+`를 사용해 토큰과 페이로드를 구분한다. 페이로드는 정수로 인코딩된다.

```http
PUT delimited_payload_example
{
  "settings": {
    "analysis": {
      "analyzer": {
        "whitespace_plus_delimited": {
          "tokenizer": "whitespace",
          "filter": [ "plus_delimited" ]
        }
      },
      "filter": {
        "plus_delimited": {
          "type": "delimited_payload",
          "delimiter": "+",
          "encoding": "int"
        }
      }
    }
  }
}
```

##### 저장된 페이로드 반환

다음 인덱스를 생성하려면 [인덱스 생성 API][create-index-api]를 사용하라:

* 페이로드와 함께 텀 벡터를 저장하는 필드를 가진 인덱스
* `delimited_payload` 필터와 함께 [커스텀 인덱스 분석기][custom-analyzer]를 사용하는 인덱스

```http
PUT text_payloads
{
  "mappings": {
    "properties": {
      "text": {
        "type": "text",
        "term_vector": "with_positions_payloads",
        "analyzer": "payload_delimiter"
      }
    }
  },
  "settings": {
    "analysis": {
      "analyzer": {
        "payload_delimiter": {
          "tokenizer": "whitespace",
          "filter": [ "delimited_payload" ]
        }
      }
    }
  }
}
```

인덱스에 페이로드를 갖는 도큐먼트를 추가한다.

```http
POST text_payloads/_doc/1
{
  "text": "the|0 brown|3 fox|4 is|0 quick|10"
}
```

[텀 벡터 API][term-vector-api]를 사용해 도큐먼트의 토큰과 Base64 인코딩된 페이로드를 반환한다.

```http
GET text_payloads/_termvectors/1
{
  "fields": [ "text" ],
  "payloads": true
}
```

API를 다음 응답을 반환한다:

```json
{
  "_index": "text_payloads",
  "_type": "_doc",
  "_id": "1",
  "_version": 1,
  "found": true,
  "took": 8,
  "term_vectors": {
    "text": {
      "field_statistics": {
        "sum_doc_freq": 5,
        "doc_count": 1,
        "sum_ttf": 5
      },
      "terms": {
        "brown": {
          "term_freq": 1,
          "tokens": [
            {
              "position": 1,
              "payload": "QEAAAA=="
            }
          ]
        },
        "fox": {
          "term_freq": 1,
          "tokens": [
            {
              "position": 2,
              "payload": "QIAAAA=="
            }
          ]
        },
        "is": {
          "term_freq": 1,
          "tokens": [
            {
              "position": 3,
              "payload": "AAAAAA=="
            }
          ]
        },
        "quick": {
          "term_freq": 1,
          "tokens": [
            {
              "position": 4,
              "payload": "QSAAAA=="
            }
          ]
        },
        "the": {
          "term_freq": 1,
          "tokens": [
            {
              "position": 0,
              "payload": "AAAAAA=="
            }
          ]
        }
      }
    }
  }
}
```







[lucene-delimited-payload-token-filter]: https://lucene.apache.org/core/8_7_0/analyzers-common/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.html
[term-vector]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/term-vector.html
[term-vector-api]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/docs-termvectors.html
[analyze-api]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/indices-analyze.html
[return-stored-payload]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-delimited-payload-tokenfilter.html#analysis-delimited-payload-tokenfilter-return-stored-payloads
[create-index-api]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/indices-create-index.html
[custom-analyzer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-custom-analyzer.html