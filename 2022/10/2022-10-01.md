# 2022. 10. 01.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰화기 레퍼런스

#### Pattern 토큰화기

`pattern` 토큰화기는 정규 표현식을 사용해 일치하는 것을 단어 구분자로 하여 텍스트를 나누거나 일치하는 텍스트를 텀으로 캡처한다.

기본 패턴은 `\W+`로, 단어가 아닌 문자마다 텍스트를 나눈다.

> ###### 잘못된(pathological) 정규표현식 사용 주의
>
> Pattern 토큰화기는 [Java 정규 표현식][java-regex]을 사용한다.
>
> 잘못 작성된 정규 표현식은 매우 느리게 실행되거나 StackOverflowError를 던져 노드가 갑자기 종료되게 만들 수 있다.
>
> [잘못된 정규 표현식과 이를 피하는 방법][regex-catastrophic]을 참고하라.

##### 예제 출력

```http
POST _analyze
{
  "tokenizer": "pattern",
  "text": "The foo_bar_size's default is 5."
}
```

위 문장은 아래 텀으로 만들어진다:

```
[ The, foo_bar_size, s, default, is, 5 ]
```

##### 구성

`pattern` 토큰화기는 다음 파라미터를 받는다:

| 파라미터  | 설명                                                         |
| --------- | ------------------------------------------------------------ |
| `pattern` | [Java 정규 표현식](https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html), 기본값은 `\W+`이다. |
| `flags`   | Java 정규 표현식 [플래그](https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html#field.summary). 플래그는 파이프로 구분된다, e.g., `"CASE_INSENSITIVE|COMMENTS"`. |
| `group`   | 토큰으로 추출할 캡처 그룹. 기본값은 `-1`(나누기)이다.        |

##### 예제 구성

이 예제에서는 `pattern` 토큰화기가 쉼표마다 텍스트를 나누도록 구성한다:

```http
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": ","
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "comma,separated,values"
}
```

위 예제는 다음 텀을 만들어낸다:

```
[ comma, separated, values ]
```

다음 예제에서는 `pattern` 토큰화기가 큰따옴표로 감싸진 값(이스케이프된 따옴표`\"`는 무시)을 캡처하도록 구성한다. 정규식은 아래처럼 생겼다:

```
"((?:\\"|[^"]|\\")*)"
```

다음과 같이 이해할 수 있다:

- 리터럴 `"`
- 캡처 시작:
  - 리터럴`\"` 혹은 `"`를 제외한 모든 문자
  - 일치하지 않는 문자가 나올 때까지 반복
- 리터럴`"`

패턴을 JSON으로 지정하면 `"`와 `\` 문자는 이스케이프해야 하므로, 최종적인 패턴은 아래와 같다:

```
\"((?:\\\\\"|[^\"]|\\\\\")+)\"
```

```http
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": "\"((?:\\\\\"|[^\"]|\\\\\")+)\"",
          "group": 1
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "\"value\", \"value with embedded \\\" quote\""
}
```

위 예제는 다음과 같이 두 개의 텀을 만들어낸다:

```
[ value, value with embedded \" quote ]
```



[java-regex]: https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html
[regex-catastrophic]: https://www.regular-expressions.info/catastrophic.html