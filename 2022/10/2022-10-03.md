# 2022. 10. 03.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰화기 레퍼런스

#### Simple Pattern split 토큰화기

`simple_pattern_split` 토큰화기는 정규 표현식을 사용해 입력을 패턴이 일치하는 부분에서 나눠 텀으로 만든다. 지원되는 정규 표현식 기능은 [`pattern`][pattern-tokenizer]보다 제한되지만 토큰화는 일반적으로 더 빠르다.

이 토큰화기는 일치하는 것은 텀으로 만들지 않는다.  동일하게 한정된 정규 표현식 서브셋에서 패턴을 사용해 일치하는 것으로 텀을 만들려면 [`simple_pattern`][simple-pattern-tokenizer] 토큰화기를 참고하라.

이 토큰화기는 [Lucene 정규 표현식][lucene-regex]을 사용한다. 지원되는 기능과 구문에 대해서는 [정규 표현식 구문][regex-syntax]을 참고하라.

기본 패턴은 빈 문자열로, 전체 입력을 가진 텀 하나만 만들어낸다. 이 토큰화기는 항상 기본값이 아닌 패턴으로 구성하는 것이 좋다.

##### 구성

`simple_pattern_split` 토큰화기는 다음 파라미터를 받는다:

| 파라미터  | 설명                                                         |
| --------- | ------------------------------------------------------------ |
| `pattern` | [Lucene 정규 표현식](https://lucene.apache.org/core/8_7_0/core/org/apache/lucene/util/automaton/RegExp.html), 기본값은 빈 문자열이다. |

##### 예제 구성

이 예제는 `simple_pattern_split` 토큰화기가 입력 텍스트를 언더스코어에서 나누도록 구성한다.

```http
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "simple_pattern_split",
          "pattern": "_"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "an_underscored_phrase"
}
```

위 예제는 다음과 같은 텀을 만들어낸다:

```
[ an, underscored, phrase ]
```



[pattern-tokenizer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-pattern-tokenizer.html
[simple-pattern-tokenizer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-simplepattern-tokenizer.html
[lucene-regex]: https://lucene.apache.org/core/8_7_0/core/org/apache/lucene/util/automaton/RegExp.html
[regex-syntax]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/regexp-syntax.html