# 2022. 10. 02.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰화기 레퍼런스

#### Simple Pattern 토큰화기

`simple_pattern` 토큰화기는 정규 표현식을 사용해 일치하는 텍스트를 텀으로 캡처한다. [`pattern`][pattern-tokenizer]보다는 지원되는 정규 표현식 기능이 제한되지만 토큰화는 일반적으로 더 빠르다.

[`pattern`][pattern-tokenizer]와 달리 이 토큰화기는 입력에서 패턴이 일치하는 곳을 나누지 않는다. 동일하게 제한된 정규 표현식 서브셋을 사용해 패턴이 일치하는 곳을 나누려면 [`simple_pattern_split`][simple-pattern-split-tokenizer] 토큰화기를 참고하라.

이 토큰화기는 [Lucene 정규 표현식][lucene-regex]을 사용한다. 지원되는 기능과 구문에 관해서는 [정규 표현식 구문][regex-syntax]을 참고하라.

기본 패턴은 빈 문자열로, 어떤 텀도 만들지 않는다. 이 토큰화기는 항상 기본 패턴이 아닌 것으로 구성해야 한다.

##### 구성

`simple_pattern` 토큰화기는 다음 파라미터를 받는다:

| 파라미터  | 설명                                                         |
| --------- | ------------------------------------------------------------ |
| `pattern` | [Lucene 정규 표현식](https://lucene.apache.org/core/8_7_0/core/org/apache/lucene/util/automaton/RegExp.html), 기본값은 빈 문자열이다. |

##### 예제 구성

이 예제는 `simple_tokenizer` 토큰화기가 세 자리 숫자를 텀으로 만들도록 구성한다.

```http
PUT my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "simple_pattern",
          "pattern": "[0123456789]{3}"
        }
      }
    }
  }
}

POST my-index-000001/_analyze
{
  "analyzer": "my_analyzer",
  "text": "fd-786-335-514-x"
}
```

위 예제는 다음 텀을 만들어낸다:

```
[ 786, 335, 514 ]
```



[pattern-tokenizer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-pattern-tokenizer.html
[simple-pattern-split-tokenizer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-simplepatternsplit-tokenizer.html
[lucene-regex]: https://lucene.apache.org/core/8_7_0/core/org/apache/lucene/util/automaton/RegExp.html
[regex-syntax]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/regexp-syntax.html