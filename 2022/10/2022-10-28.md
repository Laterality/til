# 2022. 10. 28.

## Elasticsearch(7.10)

### 텍스트 분석 - 토큰 필터 레퍼런스

#### Keyword repeat 토큰 필터

스트림에서 각 토큰의 키워드 버전을 출력한다. 이 키워드 토큰들은 스테밍되지 않는다.

`keyword_repeat` 필터는 키워드 토큰의 `keyword` 속성을 `true`로 할당한다. [`stemmer`][stemmer-token-filter]나 [`porter_stem`][porter-stem-token-filter]와 같은 스테머 토큰 필터는 `keyword` 속성이 `true`인 토큰을 건너뛴다.

`keyword_repeat` 필터를 스테머 토큰 필터와 함께 사용해 스트림에서 각 토큰의 스테밍된 버전과 스테밍되지 않은 버전을 출력할 수 있다.

> `keyword_repeat` 필터가 제대로 동작하려면 [분석기 구성][custom-analyzer]에서 스테머 토큰 필터보다 앞에 위치해야 한다.
>
> 스테밍은 모든 토큰에 영향을 미치지 않는다. 즉, 스테밍된 뒤에도 스트림이 같은 위치(postiion)의 중복되는 토큰을 가질 수 있다.
>
> 중복 토큰을 제거하려면 분석기 구성에서 스테머 필터 뒤에 [`remove_duplicates`][remove-duplicates-token-filter]를 추가하라.

`keyword_repeat` 필터는 Lucene의 [KeywordRepeatFilter][lucene-keyword-repeat-filter]를 사용한다.

##### 예제

다음 [분석 API][analyze-api] 요청은 `keyword_repeat` 필터를 사용해 `fox running and jumping`에서 각 토큰의 키워드와 비-키워드 버전을 출력한다.

토큰들의 `keyword` 속성을 반환하려면 분석 API 요청에 다음 인자를 포함해야 한다:

* `explain`: `true`
* `attributes`: `keyword`

```http
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    "keyword_repeat"
  ],
  "text": "fox running and jumping",
  "explain": true,
  "attributes": "keyword"
}
```

위 API는 다음 응답을 반환한다. 각 토큰의 한 버전의 `keyword` 속성이 `true`이다.

```json
{
  "detail": {
    "custom_analyzer": true,
    "charfilters": [],
    "tokenizer": ...,
    "tokenfilters": [
      {
        "name": "keyword_repeat",
        "tokens": [
          {
            "token": "fox",
            "start_offset": 0,
            "end_offset": 3,
            "type": "word",
            "position": 0,
            "keyword": true
          },
          {
            "token": "fox",
            "start_offset": 0,
            "end_offset": 3,
            "type": "word",
            "position": 0,
            "keyword": false
          },
          {
            "token": "running",
            "start_offset": 4,
            "end_offset": 11,
            "type": "word",
            "position": 1,
            "keyword": true
          },
          {
            "token": "running",
            "start_offset": 4,
            "end_offset": 11,
            "type": "word",
            "position": 1,
            "keyword": false
          },
          {
            "token": "and",
            "start_offset": 12,
            "end_offset": 15,
            "type": "word",
            "position": 2,
            "keyword": true
          },
          {
            "token": "and",
            "start_offset": 12,
            "end_offset": 15,
            "type": "word",
            "position": 2,
            "keyword": false
          },
          {
            "token": "jumping",
            "start_offset": 16,
            "end_offset": 23,
            "type": "word",
            "position": 3,
            "keyword": true
          },
          {
            "token": "jumping",
            "start_offset": 16,
            "end_offset": 23,
            "type": "word",
            "position": 3,
            "keyword": false
          }
        ]
      }
    ]
  }
}
```

비-키워드 토큰을 스테밍하기 위해 이전 분석 API 요청의 `keyword_repeat` 필터 뒤에 `stemmer` 필터를 추가한다.

```http
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    "keyword_repeat",
    "stemmer"
  ],
  "text": "fox running and jumping",
  "explain": true,
  "attributes": "keyword"
}
```

이 API는 다음 응답을 반환한다. 다음이 바뀌었다:

* `running`의 비-키워드 버전이 `run`으로 스테밍됐다.
* `jumping`의 비-키워드 버전이 `jump`로 스테밍됐다.

```json
{
  "detail": {
    "custom_analyzer": true,
    "charfilters": [],
    "tokenizer": ...,
    "tokenfilters": [
      {
        "name": "keyword_repeat",
        "tokens": ...
      },
      {
        "name": "stemmer",
        "tokens": [
          {
            "token": "fox",
            "start_offset": 0,
            "end_offset": 3,
            "type": "word",
            "position": 0,
            "keyword": true
          },
          {
            "token": "fox",
            "start_offset": 0,
            "end_offset": 3,
            "type": "word",
            "position": 0,
            "keyword": false
          },
          {
            "token": "running",
            "start_offset": 4,
            "end_offset": 11,
            "type": "word",
            "position": 1,
            "keyword": true
          },
          {
            "token": "run",
            "start_offset": 4,
            "end_offset": 11,
            "type": "word",
            "position": 1,
            "keyword": false
          },
          {
            "token": "and",
            "start_offset": 12,
            "end_offset": 15,
            "type": "word",
            "position": 2,
            "keyword": true
          },
          {
            "token": "and",
            "start_offset": 12,
            "end_offset": 15,
            "type": "word",
            "position": 2,
            "keyword": false
          },
          {
            "token": "jumping",
            "start_offset": 16,
            "end_offset": 23,
            "type": "word",
            "position": 3,
            "keyword": true
          },
          {
            "token": "jump",
            "start_offset": 16,
            "end_offset": 23,
            "type": "word",
            "position": 3,
            "keyword": false
          }
        ]
      }
    ]
  }
}
```

하지만 `fox`와 `and`의 키워드와 비-키워드 버전은 동일하고 각각 같은 위치에 있다.

이 중복 토큰을 제거하기 위해 분석 API 요청에서 `stemmer` 뒤에 `remove_duplicates` 필터를 추가한다.

```http
GET /_analyze
{
  "tokenizer": "whitespace",
  "filter": [
    "keyword_repeat",
    "stemmer",
    "remove_duplicates"
  ],
  "text": "fox running and jumping",
  "explain": true,
  "attributes": "keyword"
}
```

위 API는 다음과 같은 응답을 반환한다. `fox`와 `and`에 대한 중복 토큰이 제거됐다.

```json
{
  "detail": {
    "custom_analyzer": true,
    "charfilters": [],
    "tokenizer": ...,
    "tokenfilters": [
      {
        "name": "keyword_repeat",
        "tokens": ...
      },
      {
        "name": "stemmer",
        "tokens": ...
      },
      {
        "name": "remove_duplicates",
        "tokens": [
          {
            "token": "fox",
            "start_offset": 0,
            "end_offset": 3,
            "type": "word",
            "position": 0,
            "keyword": true
          },
          {
            "token": "running",
            "start_offset": 4,
            "end_offset": 11,
            "type": "word",
            "position": 1,
            "keyword": true
          },
          {
            "token": "run",
            "start_offset": 4,
            "end_offset": 11,
            "type": "word",
            "position": 1,
            "keyword": false
          },
          {
            "token": "and",
            "start_offset": 12,
            "end_offset": 15,
            "type": "word",
            "position": 2,
            "keyword": true
          },
          {
            "token": "jumping",
            "start_offset": 16,
            "end_offset": 23,
            "type": "word",
            "position": 3,
            "keyword": true
          },
          {
            "token": "jump",
            "start_offset": 16,
            "end_offset": 23,
            "type": "word",
            "position": 3,
            "keyword": false
          }
        ]
      }
    ]
  }
}
```

##### 분석기에 추가

다음 [인덱스 생성 API][create-index-api] 요청은 `keyword_repeat` 필터를 사용해 새 [커스텀 분석기][custom-analyzer]를 구성한다.

이 커스텀 분석기는 `keyword_repeat`과 `porter_stem` 필터를 사용해 스트림에서 각 토큰의 스테밍된 버전과 스테밍되지 않은 버전을 만든다. 그 다음 `remove_duplicates` 필터가 스트림에서 중복된 토큰을 제거한다.

```http
PUT /my-index-000001
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "keyword_repeat",
            "porter_stem",
            "remove_duplicates"
          ]
        }
      }
    }
  }
}
```



[stemmer-token-filter]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-stemmer-tokenfilter.html
[porter-stem-token-filter]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-porterstem-tokenfilter.html
[custom-analyzer]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-custom-analyzer.html
[remove-duplicates-token-filter]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/analysis-remove-duplicates-tokenfilter.html
[lucene-keyword-repeat-filter]: https://lucene.apache.org/core/8_7_0/analyzers-common/org/apache/lucene/analysis/miscellaneous/KeywordRepeatFilter.html