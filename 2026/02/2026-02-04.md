# 2026-02-04

## AWS Prescriptive Guidance

### RAG 애플리케이션 최적화를 위한 모범 사례 작성

대규모 언어 모델(LLMs)은 인간과 비슷한 텍스트를 이해하고 생성하는 놀랄만 한 능력과 함께 인공 지능 분야에서 진화를 이루었다. 하지만 중대한 한계에 직면해 있다. 자신의 훈련 데이터에 포함된 지식으로만 동작할 수 있다는 것이다. 여기서 [검색 증강 생성(RAG)][aws-what-is-rag]이 도움을 준다. LLMs을 조직의 데이터와 문서와 같은 외부 지식 소스와 결합하는 해법을 제시한다. 정보 검색과 응답 생성을 동반한 2단계 과정을 통해 RAG는 AI 시스템이 다양한 소스로부터 최신 정보에 접근하고 활용해 정적인(static) 모델 지식과 동적인 실세계 정보 요구의 차이를 이어  더 정확하고 지적인(informed) 응답을 가능케 한다.

RAG 기반 애플리케이션에서 검색을 위한 컨텐츠는 어떻게 최적화할 수 있을까? 이 가이드에서는 지식 베이스에 텍스트 기반 콘텐츠의 포매팅과 작성 스타일을 최적화하는 데 도움이 되는 모범 사례들을 제공한다. 컨텐츠를 최적화하면 RAG 애플리케이션이 작업에 특화된 정보를 더 정확하게 이해하는 데 도움을 주는 컨텍스트를 개선한다. 시스템이 연관도가 높고 정확한 컨텐츠를 검색하면 LLM의 응답 품질이 향상된다. 시스템 수준에서 컨텍스트 전달 과정을 최적화하는 것을 *컨텍스트 엔지니어링*이라 하며, 에이전틱 RAG 아키텍처의 필수적인 부분을 이룬다. 에이전틱 RAG에서는 하나 이상의 추가적인 LLMs이 RAG 실행 전에 추론하고 요청을 처리한다. 이는 다단계(multi-step) 정보 전달 과정을 촉진시킨다. RAG 아키텍처가 더욱 복잡해지면서 소스 컨텐츠 최적화가 LLMs에 명확한 컨텍스트를 전달하는 가장 직접적인 수단으로 남았다. 이 모범 사례들은 조직의 RAG 애플리케이션에 대한 투자를 극대화하도록 돕기 위해 설계됐다.

#### 예상 독자

이 가이드는 하나 이상의 RAG 구성요소와 함께 LLM 애플리케이션을 구축하는 AI 엔지니어, 데이터 과학자, 데이터 엔지니어 또는 소프트웨어 개발자를 위해 쓰여졌다. 이 가이드의 개념과 권고사항을 이해하려면 LLMs을 위한 벡터 데이터베이스와 프롬프트에 친숙해야 한다.

#### 목표

이 가이드의 권고사항들은 다음을 이루는 데 도움을 줄 수 있다:

- 잘 구조화되고 의미적으로 풍부한 소스 문서를 제공함으로써 토큰 사용과 중복을 최적화하고 RAG 애플리케이션이 생성한 응답의 정확도와 관련성을 향상시킨다.
- 소스 문서에 명확한 정의와 설명을 제공함으로써 RAG 애플리케이션이 도메인 특화 지식과 컨텍스트를 더 잘 이해하도록 돕는다.
- 소스 문서 간에 일관된 포맷과 구조적인 가이드라인을 더함으로써 RAG 애플리케이션을 위한 더 쉬운 유지보수와 지식 베이스 업데이트를 촉진한다.
- 큰 모놀리식 문서를 효율적으로 인덱스하고 검색할 수 있는 더 작고 자체 포함된(self-contained) 단위로 나눔으로써 RAG 솔루션의 확장성을 향상시킨다.

[aws-what-is-rag]: https://aws.amazon.com/what-is/retrieval-augmented-generation/
