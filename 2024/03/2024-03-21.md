# 2024. 03. 21.

## Elasticsearch(7.10)

### 집계 - 지표 집계

#### Percentiles 집계

##### 압축

근사치 알고리즘은 메모리 사용량과 평가 정확도 사이에 균형을 유지해야 한다. 이 균형은 `compression` 파라미터로 제어할 수 있다:

```http
GET latency/_search
{
  "size": 0,
  "aggs": {
    "load_time_outlier": {
      "percentiles": {
        "field": "load_time",
        "tdigest": {
          "compression": 200    // 1. 압축은 메모리 사용량과 근사치 오차를 제어한다
        }
      }
    }
  }
}
```

Digest 알고리즘은 백분위 근사치에 몇 개의 "노드"를 사용한다. 사용 가능한 노드가 많을수록 데이터의 볼륨에 비례해 정확도(와 메모리 사용량)가 증가한다. `compression` 파라미터는 최대 노드 수를 `20 * compression`으로 제한한다.

따라서, 압축 값을 증가시키면 더 많은 메모리를 사용하는 대신 백분위 정확도가 증가한다. 또한 큰 압축 값은 내부의 트리 자료 구조 크기를 증가시키기 때문에 연산 비용이 비싸져 알고리즘을 더 느리게 만든다. 기본 압축 값은 `100`이다.

'"노드"는 대략 32바이트 메모리를 사용하므로, 최악의 경우(대량의 데이터가 정렬된 채로 전달되면) 기본 설정은 약 64KB의 TDigest를 만들어낸다. 실제로는 데이터가 더 무작위인 경향을 띠므로 TDigest는 더 적은 메모리를 사용할 것이다.