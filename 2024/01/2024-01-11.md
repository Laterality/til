# 2024. 01. 11.

## Elasticsearch(7.10)

### 집계 - 버킷 집계

#### Significant terms 집계

##### 파라미터

###### 무엇이 최선인가?

보통, `mutual_information`은 텀이 배경에서 빈번하게 등장하는 경우에도 고빈도 텀을 선호한다. 예를 들어, 자연어 텍스트 분석에서 이는 불용어(stop word)의 선택으로 이어질 수 있다. `mutual_information`은 오타와 같이 매우 희귀한 텀을 고르는 것과는 다르다. `gnd`는 높은 동시 발생(co-occurrence)을 가진 텀을 선호하고 불용어 선택을 피한다. 동의어(synonym) 탐지에는 이것이 더 잘 맞을 수도 있다. 하지만 `gnd`는 오타와 같은 매우 희귀한 텀을 선택하는 경향이 있다. `chi_square`와 `jlh`는 그 중간이다.

서로 다른 휴리스틱 중에 어떤 것이 최선의 선택인지는 유의 텀이 무엇에 쓰이는지에 따라 다르기 때문에 정하기 어렵다. 텍스트 분류를 위한 기능 선택을 위해 유의 텀을 학습한다면 [Yang and Pedersen, "A Comparative Study on Feature Selection in Text Categorization", 1997](http://courses.ischool.berkeley.edu/i256/f06/papers/yang97comparative.pdf)을 참고해보라.

위 측정 방법들 중 여러분의 유스 케이스에 맞는 것이 없다면 또다른 선택지는 커스텀 유의성 측정을 구현하는 것이다:

###### 스크립트

스크립트를 통해 커스터마이즈된 점수 계산을 구현할 수 있다:

```json
	    "script_heuristic": {
              "script": {
	        "lang": "painless",
	        "source": "params._subset_freq/(params._superset_freq - params._subset_freq + 1)"
	      }
            }
```

스크립트는 위처럼 인라인화거나 인덱싱하거나 디스크에 저장할 수 있다. 구체적인 옵션은 [스크립트 문서](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-scripting.html)를 참고하라.

스크립트에서 사용 가능한 파라미터

| 파라미터         | 설명                                  |
| ---------------- | ------------------------------------- |
| `_subset_freq`   | 서브셋에서 텀이 등장한 도큐먼트의 수. |
| `_superset_freq` | 수퍼셋에서 텀이 등장한 도큐먼트의 수. |
| `_subset_size`   | 서브셋의 도큐먼트 수.                 |
| `_superset_size` | 수퍼셋의 도큐먼트 수.                 |

###### 크기&샤드 크기

`size` 파라미터를 설정해 전체 텀 목록에서 얼마나 많은 텀 버킷을 반환할지 정의할 수 있다. 기본적으로 검색 프로세스를 조율하는 노드는 각 샤드에 자신의 상위 텀 버킷을 요청하고 모든 샤드가 응답하면 결과를 줄여 클라이언트에 반환될 최종 목록으로 만든다. 유니크 텀의 수가 `size`보다 크다면 반환된 목록은 약간 벗어나 정확하지 않을 수 있다(텀 카운트가 약간 벗어나 반환되는 상위 크기 버킷에 들어가지 않을 수 있다).

더 나은 정확성을 보장하기 위해 최종 `size`의 배수 (`2 * (size * 1.5 + 10)`)가 각 샤드로부터 요청하는 텀의 수로 쓰인다. 이 설정을 직접 제어하려면 `shard_size` 파라미터를 사용해 각 샤드가 만들어내는 후보 텀의 양을 제어할 수 있다.

모든 결과가 조합되면 저빈도 텀이 가장 흥미로운 것이 될 수 있으므로 significant_terms 집계는 `shard_size` 파라미터가 `size`보다 유의미하게 더 높은 값으로 설정됐을 때 더 나은 품질의 결과를 만들 수 있다. 이는 더 큰 규모의 유망한 후보 텀이 최종 선택 전에 결과를 축소하는 노드에서 정리돼 검토하는 데 주어짐을 보장한다. 확실히 큰후보 텀 목록은 추가적인 네트워크 트래픽과 RAM 사용량을 필요로 하므로 품질/비용 트레이트 오프의 균형이 필요하다. `shard_size`가 -1(기본값)로 설정되면 `shard_size`는 샤드의 수와 `size` 파라미터에 따라 자동으로 평가된다.

> `shard_size`는 `size`보다 작을 수 없다. 이 경우 Elasticsearch는 이를 `size`와 같은 값으로 초기화한다.

###### 최소 도큐먼트 수

`min_doc_count` 옵션을 사용해 히트 수가 지정된 것보다 큰 텀만 반환할 수도 있다:

```http
GET /_search
{
  "aggs": {
    "tags": {
      "significant_terms": {
        "field": "tag",
        "min_doc_count": 10
      }
    }
  }
}
```

위 집계는 히트가 10 이상인 태그만 반환한다. 기본값은 `3`이다.

점수를 높게 계산하는 텀은 샤드 수준에서 수집된 다음 두 번째 단계에서 다른 샤드에서 수집된 텀들과 병합된다. 하지만 샤드는 전역 텀 빈도에 대한 정보를 사용하지 못한다. 텀이 후보 목록에 추가되는지를 결정하는 것은 단어의 전역 빈도가 아니라 로컬 샤드 빈도를 사용해 샤드에서 계산된 점수에 달려 있다. `min_doc_count` 기준은 모든 샤드의 로컬 텀 통계를 병합한 다음 적용된다. 텀을 후보로 추가하는 결정은 해당 텀이 실제로 필요한 `min_doc_count`에 도달하는지와는 관계없이 이뤄진다. 이는 빈도는 낮지만 점수는 높은 텀이 후보 목록에 포함된 경우 많은 (전역적으로) 고빈도 텀이 최종 결과에서 제외되도록 만들 수 있다. 이를 피하려면 `shard_size` 파라미터를 늘려 샤드에 더 많은 후보 텀을 허용한다. 하지만 이는 메모리 소비와 네트워크 트래픽을 증가시킨다.

###### `shard_min_doc_count`

`shard_min_doc_count` 파라미터는  `min_doc_count`에 관해 텀이 실제로 후보 목록에 추가될지 말지에 대해 샤드가 갖는 *확실성*을 조절한다. 텀은 로컬 샤드 빈도가 `shard_min_doc_count`보다 높은 경우에만 고려된다. 사전(dictionary)이 많은 저빈도 텀을 포함하고 있고 여러분이 거기에 흥미가 없다면 `shard_min_doc_count` 파라미터를 설정해 샤드 수준에서 로컬 카운트를 병합한 뒤에도 필요한 `min_doc_count`에 도달하지 않을 후보 텀을 걸러낼 수 있다. `shard_min_doc_count`는 기본적으로 `0`으로 설정돼 있으며 명시적으로 설정하지 않는 한 효과는 없다.

> `min_doc_count`를 `1`로 설정하는 것은 오타나 특이한 텀을 반환하는 경향이 있어 권장하지 않는다. 둘 이상의 텀 인스턴스를 찾는 것이 희귀하면서 결과에 텀이 잘못 포함되지 않도록 보완하는 데 도움이 된다. 기본값 `3`은 최소한의 증명력을 제공하는 데 쓰인다. `shard_min_doc_count`를 너무 높게 설정하면 유의한 후보 텀이 샤드 수준에서 걸러지게 할 수 있다. 이 값은 `min_doc_count/#shards`보다 훨씬 작아야 한다.

###### 커스텀 배경 컨텍스트

배경 텀 빈도에 대한 통계 정보의 기본 소스는 인덱스 전체이고 `background_filter`를 사용해 더 좁은 컨텍스트의 유의 텀에 초점을 맞출 수 있다:

```http
GET /_search
{
  "query": {
    "match": {
      "city": "madrid"
    }
  },
  "aggs": {
    "tags": {
      "significant_terms": {
        "field": "tag",
        "background_filter": {
          "term": { "text": "spain" }
        }
      }
    }
  }
}
```

위 필터는 인덱스 전체의 전 세계 컨텍스트에서는 흔치 않지만 단어 "Spain"을 포함한 도큐먼트의 서브셋에서 흔한 "Spanish"와 같은 텀보다 Madrid의 도시에 대해 특이한 텀에 초점을 맞추는 데 도움이 될 것이다. 

> 배경 필터를 사용하면 빈도를 결정하기 위해 텀의 포스팅이 필터링돼야 하기 때문에 쿼리가 느려진다.

###### 값 필터링

(필요한 경우가 많지 않지만)생성될 버킷에 대한 값을 필터링하는 것도 가능한다. `include`와 `exclude` 파라미터를 사용해 정규 표현식 문자열이나 정확한 텀의 배열을 전달할 수 있다. 이 기능은 [terms 집계](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html) 문서에 설명된 기능과 동일하다.

###### 수집 모드

메모리 문제를 피하기 위해 `significant_terms` 집계는 자식 집계들을 `breadth_first` 모드로 계산한다. 서로 다른 수집 모드에 대한 설명은 [terms 집계](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-collect) 문서에서 확인할 수 있다.

###### 실행 힌트

어떤 terms 집계가 실행될 수 있는지에 따라 서로 다른 메커니즘이 있다:

- 버킷 별 데이터를 수집하기 위해 필드 값을 직접 사용 (`map`)
- 필드의 [전역 순서](https://www.elastic.co/guide/en/elasticsearch/reference/current/eager-global-ordinals.html)를 사용하고 전역 순서마다 하나의 버킷을 할당 (`global_ordinals`)

Elasticsearch는 실용적인 기본값을 사용하려고 시도하므로 일반적으로 이는 설정할 필요 없다.

`global_ordinals`는 `keyword` 필드에 대한 기본값으로, 전역 순서를 사용해 버킷을 동적으로 할당하므로 메모리 사용량이 집계 범위에 해당하는 도큐먼트의 값의 수에 따라 선형적이다.

`map`은 매우 적은 수의 도큐먼트가 쿼리에 일치하는 경우에만 고려된다. 그 외에는 순서 기반 실행 모드가 확실히 빠르다. 기본적으로 `map`은 순서를 갖지 않기 때문에 스크립트에서 집계를 실행할 때 쓰인다.

```http
GET /_search
{
  "aggs": {
    "tags": {
      "significant_terms": {
        "field": "tags",
        "execution_hint": "map" // 1. 사용할 수 있는 값은 `map`, `global_ordinals`이다
      }
    }
  }
}
```

Elasticsearch는 이 실행 힌트를 적용할 수 없는 경우 무시한다.