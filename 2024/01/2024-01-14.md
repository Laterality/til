# 2024. 01. 14.

## Elasticsearch(7.10)

### 집계 - 버킷 집계

#### Significant text 집계

##### `filter_duplicate_text`를 사용해 노이즈가 있는 데이터 다루기

자유 텍스트 필드는 종종 원래 내용과 기계적으로 복사된 텍스트(복사-붙여넣기한 전기(biography), 이메일 답장들, 리트윗, 보일러플레이터 헤더/푸터, 페이지 탐색 메뉴, 사이드바 뉴스 링크, 저작권 고지, 표준 면책(disclaimer)고지, 주소)이 섞여 포함될 수 있다.

실세계에서 이런 중복 텍스트 섹션은 필터링되지 않으면 `significant_text`에 포함되는 경향이 있다. 인덱스 시점에 준 중복(near-duplicate) 텍스트를 필터링하는 것은 어려운 작업이지만 `filter_duplicate_text` 설정을 사용해 쿼리 시점에 필요에 따라 데이터를 정리할 수 있다.

먼저 전 세계의 다양한 뉴스 기사 백만 개로 이루어진 [Signal media dataset][signal-media-dataset]을 사용해 필터링되지 않은 실세계 예시를 살펴보자. 원본(raw) 텍스트에 대해 "elasticsearch"를 언급한 기사를 검색한 결과는 아래와 같다:

```json
{
  ...
  "aggregations": {
    "sample": {
      "doc_count": 35,
      "keywords": {
        "doc_count": 35,
        "buckets": [
          {
            "key": "elasticsearch",
            "doc_count": 35,
            "score": 28570.428571428572,
            "bg_count": 35
          },
          ...
          {
            "key": "currensee",
            "doc_count": 8,
            "score": 6530.383673469388,
            "bg_count": 8
          },
          ...
          {
            "key": "pozmantier",
            "doc_count": 4,
            "score": 3265.191836734694,
            "bg_count": 4
          },
          ...

}
```

정리되지 않은 도큐먼트는 언뜻 보기에 검색 텀 "elasticsearch"의 외관과 통계적으로 연관이 있어보이는 "pozmantier"와 같은 이상해보이는 텀을 반환한다. 아래 쿼리를 사용해 이 도큐먼트들을 더 파고들어 pozmantier가 왜 연관되는지 살펴보자:

```http
GET news/_search
{
  "query": {
    "simple_query_string": {
      "query": "+elasticsearch  +pozmantier"
    }
  },
  "_source": [
    "title",
    "source"
  ],
  "highlight": {
    "fields": {
      "content": {}
    }
  }
}
```

결과는 몇 가지 기술 프로젝트의 심사위원에 관한 매유 유사한 뉴스 기사들을 보여준다:

```json
{
  ...
  "hits": {
    "hits": [
      {
        ...
        "_source": {
          "source": "Presentation Master",
          "title": "T.E.N. Announces Nominees for the 2015 ISE® North America Awards"
        },
        "highlight": {
          "content": [
            "City of San Diego Mike <em>Pozmantier</em>, Program Manager, Cyber Security Division, Department of",
            " Janus, Janus <em>ElasticSearch</em> Security Visualization Engine "
          ]
        }
      },
      {
        ...
        "_source": {
          "source": "RCL Advisors",
          "title": "T.E.N. Announces Nominees for the 2015 ISE(R) North America Awards"
        },
        "highlight": {
          "content": [
            "Mike <em>Pozmantier</em>, Program Manager, Cyber Security Division, Department of Homeland Security S&T",
            "Janus, Janus <em>ElasticSearch</em> Security Visualization Engine"
          ]
        }
      },
      ...
```

Mike Pozmantier는 수많은 심사위원 중 하나였고 elasticsearch는 심사받는 많은 프로젝트 중 하나에서 사용된 것이었다.

전형적으로 이렇게 긴 기사는 여러 뉴스 사이트에 복사-붙여넣기돼 결과적으로 희귀한 이름, 숫자 혹은 오타가 일치하는는 쿼리와 통계적으로 연관이 있게 된다.

다행히 유사한 도큐먼트는 랭크가 비슷하게 매겨지는 경향이 있기 때문에 상위 일치 도큐먼트의 스트림을 시험하는 일부분으로 significant_text 집계는 이미 본 6개 이상의 토큰을 제거하는 필터를 적용할 수 있다. 이번에는 `filter_duplicate_text` 설정을 켜고 같은 쿼리를 실행해보자:

```http
GET news/_search
{
  "query": {
    "match": {
      "content": "elasticsearch"
    }
  },
  "aggs": {
    "sample": {
      "sampler": {
        "shard_size": 100
      },
      "aggs": {
        "keywords": {
          "significant_text": {
            "field": "content",
            "filter_duplicate_text": true
          }
        }
      }
    }
  }
}
```

중복이 제거된 텍스트를 분석한 결과는 elastic 스택에 익숙한 누가 보더라도 확실히 품질이 나아졌다:

```json
{
  ...
  "aggregations": {
    "sample": {
      "doc_count": 35,
      "keywords": {
        "doc_count": 35,
        "buckets": [
          {
            "key": "elasticsearch",
            "doc_count": 22,
            "score": 11288.001166180758,
            "bg_count": 35
          },
          {
            "key": "logstash",
            "doc_count": 3,
            "score": 1836.648979591837,
            "bg_count": 4
          },
          {
            "key": "kibana",
            "doc_count": 3,
            "score": 1469.3020408163263,
            "bg_count": 5
          }
        ]
      }
    }
  }
}
```

복사-붙여넣기 혹은 기계적인 반복의 결과로 Pozmantier씨와 다른 elasticsearch 관계자들은 더이상 집게 결과에 나타나지 않는다.

여러분의 중복 혹은 준 중복 내용이 인덱스된 단일 값 필드(아마도 기사의 `title` 텍스트나 `original_press_release_url`에 대한 해시 필드)로 식별 가능하다면 부모 [diversified sampler][agg-diversified-sampler] 집계를 사용해 단일 키에 따라 샘플 집합에서 이러한 도큐먼트를 제거하는 것이 더 효율적일 것이다. significant_text 집계에 들어가는 내용에 중복이 적을수록 성능도 좋아진다.

> **유의성 점수의 계산 방법**
>
> 점수로 반환된 숫자는 최종 사용자가 쉽게 이해하기 위한 것보다는 주로 서로 다른 제안들에 랭킹을 매기기 위한 것이다. 이 점수는 *전경*과 *배경* 집합의 도큐먼트 빈도에서 파생된다. 간단히 설명하면, 배경에서와 서브셋에서 나타나는 텀의 빈도에 주목할만한 차이가 있다면 이 텀은 유의한 것으로 간주된다. 텀의 랭킹을 매기는 방법은 설정할 수 있다. "파라미터" 섹션 참고.

> **"*이거 말고 비슷한 거*"(like this but not this) 패턴 사용**
>
> `category:adultMovie`와 같은 구조화된 필드를 먼저 검색한 다음 자유 텍스트인 `movie_description` 필드에 significant_terms`를 사용해 잘못 카테고리화된 내용을 조명할 수 있다. 제안된 단어들을 가지고 category:adultMovie로 표시되지 않은 모든 영화를 검색한다. 이제 잘못 카테고리화돼 다시 분류하거나 적어도 "가족과 함께 보기 좋은" 카테고리에서 제거할 영화 목록이 된다.
>
> 각 텀의 중요도 점수는 일치 항목을 정렬하는 유용한 `boost` 설정을 제공한다. 키워드를 사용한 `terms` 쿼리의 `minimum_should_match` 설정이 결과 집합에서 정밀도/재현율(recall)의 균형을 제어하는 것을 돕는다. 즉, 높은 설정은 모든 키워드가 포함된 적은 수의 연관 결과를 갖고 "1"로 설정하면 어떤 키워드든 포함한 모든 도큐먼트 집합을 만들어낼 것이다.



[signal-media-dataset]: https://research.signalmedia.co/newsir16/signal-dataset.html
[agg-diversified-sampler]: https://www.elastic.co/guide/en/elasticsearch/reference/7.10/search-aggregations-bucket-diversified-sampler-aggregation.html